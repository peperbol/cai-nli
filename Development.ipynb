{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"nli\"\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "x = pd.DataFrame(columns=['Text', 'Word', 'POS', 'Tag', 'Dependency'])\n",
    "z = pd.DataFrame(columns = [''])\n",
    "\n",
    "cnt = 1\n",
    "for filename in os.listdir(data_directory):\n",
    "    y, _ = filename.split(\"_\")\n",
    "    doc = nlp(open(os.path.join(data_directory, filename), \"r\").read())\n",
    "    print(f'Now processing text: {filename}, text {cnt} of {len(os.listdir(data_directory))}')\n",
    "    cnt += 1\n",
    "\n",
    "    for token in doc:\n",
    "        x = x.append({'Text': _, 'Word': token.text, 'POS': token.pos_, 'Tag' : token.tag_, 'Dependency' : token.dep_}, ignore_index=True)\n",
    "    \n",
    "Y.append(y)\n",
    "#X.append(x)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing text: TUR_10828.txt, text 1 of 20\n",
      "Now processing text: ITA_10137.txt, text 2 of 20\n",
      "Now processing text: JPN_2037.txt, text 3 of 20\n",
      "Now processing text: TUR_10803.txt, text 4 of 20\n",
      "Now processing text: TUR_10817.txt, text 5 of 20\n",
      "Now processing text: JPN_2080.txt, text 6 of 20\n",
      "Now processing text: ITA_10156.txt, text 7 of 20\n",
      "Now processing text: JPN_1993.txt, text 8 of 20\n",
      "Now processing text: JPN_1986.txt, text 9 of 20\n",
      "Now processing text: ITA_10145.txt, text 10 of 20\n",
      "Now processing text: ARA_146.txt, text 11 of 20\n",
      "Now processing text: JPN_2088.txt, text 12 of 20\n",
      "Now processing text: ARA_154.txt, text 13 of 20\n",
      "Now processing text: ARA_140.txt, text 14 of 20\n",
      "Now processing text: TUR_10834.txt, text 15 of 20\n",
      "Now processing text: ARA_125.txt, text 16 of 20\n",
      "Now processing text: ITA_10111.txt, text 17 of 20\n",
      "Now processing text: ARA_122.txt, text 18 of 20\n",
      "Now processing text: ITA_10106.txt, text 19 of 20\n",
      "Now processing text: TUR_10830.txt, text 20 of 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#################################################\n",
    "#\tGeneration of the dataframe containing the \t#\n",
    "#\traw training text and their assigned labels\t#\n",
    "#################################################\n",
    "\n",
    "df = pd.DataFrame(columns = ['label', 'text'])\n",
    "\n",
    "cnt = 1\n",
    "\n",
    "data_directory = 'nli2'\n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    print(f'Now processing text: {filename}, text {cnt} of {len(os.listdir(data_directory))}')\n",
    "    cnt += 1\n",
    "    \n",
    "    label_, _ = filename.split(\"_\")\n",
    "    doc_ = open(f'{data_directory}/{filename}', 'r').read()\n",
    "    \n",
    "    df = df.append({'label': label_, 'text': doc_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TUR</td>\n",
       "      <td>\\tToday, we are living in an age of consumptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ITA</td>\n",
       "      <td>The idea that young people nowadays do not dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>JPN</td>\n",
       "      <td>I agree with the statement as it says, the be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TUR</td>\n",
       "      <td>I do not agree that younger people enjoy life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TUR</td>\n",
       "      <td>While I was in school I was very unhappy when ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   TUR  \\tToday, we are living in an age of consumptio...\n",
       "1   ITA  The idea that young people nowadays do not dev...\n",
       "2   JPN   I agree with the statement as it says, the be...\n",
       "3   TUR  I do not agree that younger people enjoy life ...\n",
       "4   TUR  While I was in school I was very unhappy when ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(r'testje.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TUR</td>\n",
       "      <td>Life is all about the preferences. some people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TEL</td>\n",
       "      <td>\\tI agree with the statement that \"Most advert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FRE</td>\n",
       "      <td>\\tIn today's society, advertisement is the sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SPA</td>\n",
       "      <td>I am agree with the statement. I think that pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KOR</td>\n",
       "      <td>\\tSome people may think that the older people ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   TUR  Life is all about the preferences. some people...\n",
       "1   TEL  \\tI agree with the statement that \"Most advert...\n",
       "2   FRE  \\tIn today's society, advertisement is the sou...\n",
       "3   SPA  I am agree with the statement. I think that pe...\n",
       "4   KOR  \\tSome people may think that the older people ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = pd.read_csv('training_dataset.csv', index_col = 0)\n",
    "\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tr['text']\n",
    "y = tr['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7370, 43584)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7370, 43584)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239   9  11   3  14   3   7  11  20  12  17]\n",
      " [  3 249   3   1   4   1  19  29   1   2  17]\n",
      " [  8   7 256  12   7  18   0   6  12   1   1]\n",
      " [  4   6   7 274   2   8   2   2   9   2   4]\n",
      " [  7   3   1   6 240   0   1   1   4  68   3]\n",
      " [  4   7  18   6   1 269   1   3  20   2   5]\n",
      " [  1  13   5   5   1   2 222  43  11   4   6]\n",
      " [  4  31   4   3   3   1  41 228   6   7   6]\n",
      " [ 16   7  17   7   6  20   3   4 221   4  17]\n",
      " [  6   4   2   3  65   0   2   1   2 243   1]\n",
      " [ 12  11   8  12  14   5   5   9  10   3 250]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.79      0.69      0.74       346\n",
      "         CHI       0.72      0.76      0.74       329\n",
      "         FRE       0.77      0.78      0.78       328\n",
      "         GER       0.83      0.86      0.84       320\n",
      "         HIN       0.67      0.72      0.69       334\n",
      "         ITA       0.82      0.80      0.81       336\n",
      "         JPN       0.73      0.71      0.72       313\n",
      "         KOR       0.68      0.68      0.68       334\n",
      "         SPA       0.70      0.69      0.69       322\n",
      "         TEL       0.70      0.74      0.72       329\n",
      "         TUR       0.76      0.74      0.75       339\n",
      "\n",
      "    accuracy                           0.74      3630\n",
      "   macro avg       0.74      0.74      0.74      3630\n",
      "weighted avg       0.74      0.74      0.74      3630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linguistic_and_stylistic_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('testje.csv', index_col = 0)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \\tToday, we are living in an age of consumptio...\n",
       "1     The idea that young people nowadays do not dev...\n",
       "2      I agree with the statement as it says, the be...\n",
       "3     I do not agree that younger people enjoy life ...\n",
       "4     While I was in school I was very unhappy when ...\n",
       "5     I agree with the opinion. These days, In Japan...\n",
       "6     Traffic, a rapid increase in fuel price and it...\n",
       "7     \\tIt is a difficult question, but for me, the ...\n",
       "8          I definetely agree with the statement tha...\n",
       "9     I am agree with this statement because if a st...\n",
       "10         Every one try to look for enjoyment in hi...\n",
       "11       Some people think that  it is the best way ...\n",
       "12    Broad knowledge of many academic subjects than...\n",
       "13    \\tAlthogh, some people think that students nee...\n",
       "14       Are you young? you have to know the importa...\n",
       "15    In the past , people was not having any idea a...\n",
       "16    If I had to refer only to my personal experien...\n",
       "17      According to what all government say, that a...\n",
       "18    This statement seems like a biblical rivelatio...\n",
       "19    The purpose of advertisements is to convince p...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy    \n",
    "model = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'ssc_data'\n",
    "if not os.path.isdir(mypath):\n",
    "   os.makedirs(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('testje.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1 of 20\n",
      "Processing text 2 of 20\n",
      "Processing text 3 of 20\n",
      "Processing text 4 of 20\n",
      "Processing text 5 of 20\n",
      "Processing text 6 of 20\n",
      "Processing text 7 of 20\n",
      "Processing text 8 of 20\n",
      "Processing text 9 of 20\n",
      "Processing text 10 of 20\n",
      "Processing text 11 of 20\n",
      "Processing text 12 of 20\n",
      "Processing text 13 of 20\n",
      "Processing text 14 of 20\n",
      "Processing text 15 of 20\n",
      "Processing text 16 of 20\n",
      "Processing text 17 of 20\n",
      "Processing text 18 of 20\n",
      "Processing text 19 of 20\n",
      "Processing text 20 of 20\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "i = 0\n",
    "\n",
    "for doc_ in texts['text']:\n",
    "    print(f'Processing text {cnt} of {len(texts)}')\n",
    "    conll = []\n",
    "    doc = model(doc_)\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            row = [str(token.i - sent.start), token.text, token.pos_, str(token.head.i - sent.start), token.dep_, '_']\n",
    "            conll.append(row)\n",
    "            if token.i + 1 == sent.end:\n",
    "                conll.append(['\\n'])                \n",
    "\n",
    "\n",
    "    '''\n",
    "    Write new file\n",
    "    '''\n",
    "    \n",
    "    t = '\\t'\n",
    "    \n",
    "    with open(f'{mypath}/{i}.txt', 'w+') as f: #Testen\n",
    "        for line in conll:\n",
    "            f.write(t.join(line))\n",
    "            f.write('\\n')\n",
    "\n",
    "    cnt += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linguistic_and_stylistic_complexity.bin import lascomplexity as ssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
